{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gui/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label    I1        I2    I3    I4        I5     I6    I7    I8     I9  ...  \\\n",
      "0      0  0.05  0.006633  0.05  0.00  0.021594  0.008  0.15  0.04  0.362  ...   \n",
      "1      0  0.10  0.004975  0.44  0.02  0.001594  0.016  0.02  0.04  0.008  ...   \n",
      "2      0  0.10  0.004975  0.01  0.28  0.011984  0.178  0.04  0.04  0.490  ...   \n",
      "3      0  0.00  1.000000  0.00  0.00  0.068625  0.000  0.00  0.00  0.000  ...   \n",
      "4      0  0.15  0.003317  0.00  0.00  0.000031  0.000  0.03  0.00  0.000  ...   \n",
      "\n",
      "       C17      C18      C19      C20      C21      C22      C23      C24  \\\n",
      "0  1528982  1529013  1533925  1536019  1556876  1934144  1934164  1936312   \n",
      "1  1528983  1529008  1533925  1536020  1536034  1934144  1934164  1934195   \n",
      "2  1528988  1529304  1533924  1536018  1536025  1934145  1934164  1934181   \n",
      "3  1528989  1529022  1533924  1536018  1536022  1934144  1934164  1934185   \n",
      "4  1528989  1529288  1533924  1536018  1536038  1934144  1934163  1934180   \n",
      "\n",
      "       C25      C26  \n",
      "0  2022803  2024738  \n",
      "1  2022803  2022906  \n",
      "2  2022801  2022897  \n",
      "3  2022801  2022897  \n",
      "4  2022801  2022897  \n",
      "\n",
      "[5 rows x 40 columns]\n",
      "(330033, 27)\n",
      "Index(['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11',\n",
      "       'C12', 'C13', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21',\n",
      "       'C22', 'C23', 'C24', 'C25', 'C26', 'label'],\n",
      "      dtype='object')\n",
      "{'label': 2, 'C9': 3, 'C20': 4, 'C17': 10, 'C22': 13, 'C6': 14, 'C23': 15, 'C14': 26, 'C25': 61, 'C5': 211, 'C8': 426, 'C2': 524, 'C1': 906, 'C19': 1623, 'C13': 2995, 'C18': 3254, 'C11': 4341, 'C15': 7110, 'C7': 9601, 'C26': 16941, 'C10': 19111, 'C24': 21462, 'C4': 40131, 'C3': 43361, 'C12': 43823, 'C21': 44245, 'C16': 44666}\n",
      "C1          1407\n",
      "C2          2025\n",
      "C3        415604\n",
      "C4        664143\n",
      "C5        664504\n",
      "C6        664535\n",
      "C7        676692\n",
      "C8        677339\n",
      "C9        677369\n",
      "C10       732010\n",
      "C11       737368\n",
      "C12      1147327\n",
      "C13      1150506\n",
      "C14      1150537\n",
      "C15      1163007\n",
      "C16      1528936\n",
      "C17      1528991\n",
      "C18      1533889\n",
      "C19      1536012\n",
      "C20      1536021\n",
      "C21      1934139\n",
      "C22      1934160\n",
      "C23      1934177\n",
      "C24      2022699\n",
      "C25      2022880\n",
      "C26      2086933\n",
      "label          1\n",
      "dtype: int64\n",
      "C1 has 906 classes\n",
      "C2 has 524 classes\n",
      "C3 has 43361 classes\n",
      "C4 has 40131 classes\n",
      "C5 has 211 classes\n",
      "C6 has 14 classes\n",
      "C7 has 9601 classes\n",
      "C8 has 426 classes\n",
      "C9 has 3 classes\n",
      "C10 has 19111 classes\n",
      "C11 has 4341 classes\n",
      "C12 has 43823 classes\n",
      "C13 has 2995 classes\n",
      "C14 has 26 classes\n",
      "C15 has 7110 classes\n",
      "C16 has 44666 classes\n",
      "C17 has 10 classes\n",
      "C18 has 3254 classes\n",
      "C19 has 1623 classes\n",
      "C20 has 4 classes\n",
      "C21 has 44245 classes\n",
      "C22 has 13 classes\n",
      "C23 has 15 classes\n",
      "C24 has 21462 classes\n",
      "C25 has 61 classes\n",
      "C26 has 16941 classes\n",
      "label has 2 classes\n",
      "[906, 524, 43361, 40131, 211, 14, 9601, 426, 3, 19111, 4341, 43823, 2995, 26, 7110, 44666, 10, 3254, 1623, 4, 44245, 13, 15, 21462, 61, 16941, 2]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "\n",
    "# Model Hyperparameters\n",
    "\n",
    "dataset_path = './criteo/train.csv'\n",
    "\n",
    "cuda = True\n",
    "DEVICE = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "x_dim  = 784\n",
    "hidden_dim = 400\n",
    "\n",
    "\n",
    "lr = 1e-5\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "\n",
    "df = pd.read_csv(dataset_path)\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "columns_to_keep = [col for col in df.columns if col.startswith('C')]\n",
    "columns_to_keep.append(\"label\")\n",
    "filtered_df = df[columns_to_keep]\n",
    "\n",
    "# Print the shape of the filtered DataFrame\n",
    "print(filtered_df.shape)\n",
    "# Print the columns of the filtered DataFrame\n",
    "print(filtered_df.columns)\n",
    "# Print the number of unique values in each column of the filtered DataFrame\n",
    "num_classes = filtered_df.nunique().sort_values().to_dict()\n",
    "print(num_classes)\n",
    "print(filtered_df.max())\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    A simple implementation of Gaussian MLP Encoder and Decoder\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.FC_input = nn.Linear(input_dim, hidden_dim)\n",
    "        self.LayerNorm1 = nn.LayerNorm(hidden_dim)\n",
    "        self.FC_input2 = nn.Linear(hidden_dim, latent_dim*2)\n",
    "        self.LayerNorm2 = nn.LayerNorm( latent_dim*2)\n",
    "        self.FC_mean = nn.Linear( latent_dim*2, latent_dim)\n",
    "        self.FC_var = nn.Linear( latent_dim*2, latent_dim)\n",
    "        \n",
    "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.LeakyReLU(self.LayerNorm1(self.FC_input(x)))\n",
    "        h = self.LeakyReLU(self.LayerNorm2(self.FC_input2(h)))\n",
    "\n",
    "        \n",
    "        return h\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.FC_hidden = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.LayerNorm1 = nn.LayerNorm(hidden_dim)\n",
    "        self.FC_hidden2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.LayerNorm2 = nn.LayerNorm(hidden_dim)\n",
    "        self.FC_output = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.LeakyReLU(self.LayerNorm1(self.FC_hidden(x)))\n",
    "        h = self.LeakyReLU(self.LayerNorm2(self.FC_hidden2(h)))\n",
    "        x_hat = torch.nn.functional.log_softmax(self.FC_output(h), dim=1)\n",
    "        return x_hat\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, Encoder, Decoder):\n",
    "        super(Model, self).__init__()\n",
    "        self.Encoder = Encoder\n",
    "        self.Decoder = Decoder\n",
    "        \n",
    "    def reparameterization(self, mean, var):\n",
    "        epsilon = torch.randn_like(var).to(DEVICE)\n",
    "        z = mean + var * epsilon\n",
    "        return z\n",
    "        \n",
    "    def encode(self, x):\n",
    "        h = self.Encoder(x)\n",
    "        return h\n",
    "    \n",
    "    def decode(self, z):\n",
    "        x_hat = self.Decoder(z)\n",
    "        return x_hat\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean, log_var = self.Encoder(x)\n",
    "        z = self.reparameterization(mean, torch.exp(0.5 * log_var))\n",
    "        x_hat = self.Decoder(z)\n",
    "        \n",
    "        return x_hat, mean, log_var\n",
    "\n",
    "class ModelsMap(nn.Module):\n",
    "    def __init__(self, columns_to_keep, num_classes, hidden_dim, latent_dim, device):\n",
    "        super(ModelsMap, self).__init__()\n",
    "        self.models = nn.ModuleDict()\n",
    "        self.num_classes = []\n",
    "        self.latent_num_classes = []\n",
    "        self.activation = nn.ReLU()\n",
    "        for col in columns_to_keep:\n",
    "            self.num_classes.append(num_classes[col])\n",
    "            print(f\"{col} has {num_classes[col]} classes\")\n",
    "            self.latent_num_classes.append(latent_dim)\n",
    "            encoder = Encoder(input_dim=num_classes[col], hidden_dim=hidden_dim, latent_dim=latent_dim)\n",
    "            decoder = Decoder(latent_dim=latent_dim, hidden_dim=hidden_dim, output_dim=num_classes[col])\n",
    "            model = Model(Encoder=encoder, Decoder=decoder).to(device)\n",
    "            self.models[col] = model\n",
    "        self.latent_size = len(columns_to_keep) * latent_dim\n",
    "        self.mean_projector = nn.Linear(self.latent_size*2, self.latent_size*3).to(device)\n",
    "\n",
    "        self.mean_projector_1 = nn.Linear(self.latent_size*3, self.latent_size).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        hs = []\n",
    "        for k, v in x.items():\n",
    "            h = self.models[k].encode(v)\n",
    "            hs.append(h)\n",
    "        hs_ = self.mean_projector(torch.cat(hs, dim=1))\n",
    "        hs_ = self.activation(hs_)\n",
    "        hs_=self.mean_projector_1(hs_)\n",
    "        hs_ = torch.split(hs_, self.latent_num_classes, dim=1)\n",
    "        output = {}\n",
    "        for idx, (k, v) in enumerate(x.items()):\n",
    "            mean = self.models[k].Encoder.FC_mean(hs[idx])\n",
    "            # var = self.models[k].Encoder.FC_var(hs[idx])\n",
    "            # z = self.models[k].reparameterization(mean, torch.exp(0.5 * var))\n",
    "            z=mean\n",
    "            x_hat = self.models[k].decode(z)\n",
    "            output[k] = [x_hat, 0, 0]\n",
    "        return output\n",
    "    def encode(self,x):\n",
    "        hs = []\n",
    "        for k, v in x.items():\n",
    "            h = self.models[k].encode(v)\n",
    "            hs.append(h)\n",
    "        hs_ = self.mean_projector(torch.cat(hs, dim=1))\n",
    "        hs_ = self.activation(hs_)\n",
    "        hs_=self.mean_projector_1(hs_)\n",
    "        hs_ = torch.split(hs_, self.latent_num_classes, dim=1)\n",
    "        output = {}\n",
    "        for idx, (k, v) in enumerate(x.items()):\n",
    "            z = self.models[k].Encoder.FC_mean(hs[idx])\n",
    "            output[k] = z\n",
    "        return output\n",
    "columns_to_keep = ['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11',\n",
    "       'C12', 'C13', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21',\n",
    "       'C22', 'C23', 'C24', 'C25', 'C26',\"label\"]\n",
    "model = ModelsMap(columns_to_keep, num_classes, hidden_dim, 4, DEVICE)         \n",
    "model.load_state_dict(torch.load('nov_model_weights.pth'))\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the criteox_1 dataset\n",
    "dataset = load_dataset('./criteo')\n",
    "test_dataset = dataset[\"train\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "# create a dict with default values as {}\n",
    "from collections import defaultdict\n",
    "c_dict = defaultdict(dict)\n",
    "for col in columns_to_keep:\n",
    "    for i,v in enumerate(set(df[col])):\n",
    "        c_dict[col][v] = i\n",
    "\n",
    "# print(c_dict)\n",
    "import json\n",
    "with open('c_dict.json', 'w') as fp:\n",
    "    json.dump(c_dict, fp)\n",
    "print([num_classes[col] for col in columns_to_keep])\n",
    "model.eval()\n",
    "    \n",
    "C5_test_dataset = test_dataset.map(lambda x:{col+\"_I\":c_dict[col][x[col]] for col in columns_to_keep},num_proc=32)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "total = len(C5_test_dataset)\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size=128\n",
    "result = defaultdict(lambda: [])\n",
    "\n",
    "for batch_idx, x in enumerate(DataLoader(C5_test_dataset, batch_size=batch_size)):\n",
    "    xs = {}\n",
    "    x_onehots = {}\n",
    "    for col in columns_to_keep:\n",
    "        x_=x[col+\"_I\"].to(DEVICE)\n",
    "        xs[col]=x_\n",
    "        x_onehot = torch.nn.functional.one_hot(x_,num_classes[col]).float()\n",
    "        x_onehots[col]=x_onehot\n",
    "    output = model.encode(x_onehots)\n",
    "    for k,v in x.items():\n",
    "        if k in columns_to_keep and k!=\"label\":\n",
    "            for i in range(output[k].shape[1]):\n",
    "                result[k+\"_\"+str(i)].extend(output[k][:,i].tolist())\n",
    "        elif k.startswith(\"I\") or k==\"label\":\n",
    "            result[k].extend(v.tolist())\n",
    "\n",
    "\n",
    "\n",
    "print(\"Finish!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>...</th>\n",
       "      <th>C24_2</th>\n",
       "      <th>C24_3</th>\n",
       "      <th>C25_0</th>\n",
       "      <th>C25_1</th>\n",
       "      <th>C25_2</th>\n",
       "      <th>C25_3</th>\n",
       "      <th>C26_0</th>\n",
       "      <th>C26_1</th>\n",
       "      <th>C26_2</th>\n",
       "      <th>C26_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008292</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.160344</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512861</td>\n",
       "      <td>0.644118</td>\n",
       "      <td>-0.928199</td>\n",
       "      <td>-0.597961</td>\n",
       "      <td>-0.338730</td>\n",
       "      <td>-0.221025</td>\n",
       "      <td>-0.335736</td>\n",
       "      <td>0.578361</td>\n",
       "      <td>-0.098838</td>\n",
       "      <td>-0.258672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003317</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.077438</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.194</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.285203</td>\n",
       "      <td>0.720501</td>\n",
       "      <td>-0.596027</td>\n",
       "      <td>0.379560</td>\n",
       "      <td>-0.580749</td>\n",
       "      <td>-0.310848</td>\n",
       "      <td>-1.204171</td>\n",
       "      <td>-0.125809</td>\n",
       "      <td>0.276610</td>\n",
       "      <td>-0.112444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.533997</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.176</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103438</td>\n",
       "      <td>1.001045</td>\n",
       "      <td>-0.596027</td>\n",
       "      <td>0.379560</td>\n",
       "      <td>-0.580749</td>\n",
       "      <td>-0.310848</td>\n",
       "      <td>-1.204171</td>\n",
       "      <td>-0.125809</td>\n",
       "      <td>0.276610</td>\n",
       "      <td>-0.112444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097844</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.002</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.285203</td>\n",
       "      <td>0.720501</td>\n",
       "      <td>-0.596027</td>\n",
       "      <td>0.379560</td>\n",
       "      <td>-0.580749</td>\n",
       "      <td>-0.310848</td>\n",
       "      <td>-1.204171</td>\n",
       "      <td>-0.125809</td>\n",
       "      <td>0.276610</td>\n",
       "      <td>-0.112444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003317</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.126</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.285203</td>\n",
       "      <td>0.720501</td>\n",
       "      <td>-0.596027</td>\n",
       "      <td>0.379560</td>\n",
       "      <td>-0.580749</td>\n",
       "      <td>-0.310848</td>\n",
       "      <td>-1.204171</td>\n",
       "      <td>-0.125809</td>\n",
       "      <td>0.276610</td>\n",
       "      <td>-0.112444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label   I1        I2    I3    I4        I5     I6    I7    I8     I9  ...  \\\n",
       "0      1  0.0  0.008292  0.11  0.10  0.160344  0.068  0.02  0.08  0.010  ...   \n",
       "1      0  0.0  0.003317  0.00  0.00  0.077438  0.000  0.00  0.74  0.194  ...   \n",
       "2      1  1.0  0.533997  0.00  0.08  0.000078  0.008  0.89  0.80  0.176  ...   \n",
       "3      0  0.0  0.097844  0.02  0.00  0.000000  0.000  0.00  0.00  0.002  ...   \n",
       "4      0  0.0  0.003317  0.00  0.00  1.000000  0.284  0.00  0.14  0.126  ...   \n",
       "\n",
       "      C24_2     C24_3     C25_0     C25_1     C25_2     C25_3     C26_0  \\\n",
       "0  0.512861  0.644118 -0.928199 -0.597961 -0.338730 -0.221025 -0.335736   \n",
       "1 -0.285203  0.720501 -0.596027  0.379560 -0.580749 -0.310848 -1.204171   \n",
       "2 -0.103438  1.001045 -0.596027  0.379560 -0.580749 -0.310848 -1.204171   \n",
       "3 -0.285203  0.720501 -0.596027  0.379560 -0.580749 -0.310848 -1.204171   \n",
       "4 -0.285203  0.720501 -0.596027  0.379560 -0.580749 -0.310848 -1.204171   \n",
       "\n",
       "      C26_1     C26_2     C26_3  \n",
       "0  0.578361 -0.098838 -0.258672  \n",
       "1 -0.125809  0.276610 -0.112444  \n",
       "2 -0.125809  0.276610 -0.112444  \n",
       "3 -0.125809  0.276610 -0.112444  \n",
       "4 -0.125809  0.276610 -0.112444  \n",
       "\n",
       "[5 rows x 118 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"latent_criteo/train.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlcore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
